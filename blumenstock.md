# Response to Blumenstock
Fahmi Islam —

January 27

[Article](https://www.nature.com/magazine-assets/d41586-018-06215-5/d41586-018-06215-5.pdf) 

[Question](https://github.com/wicked-problems/workshop/blob/master/blumenstock.md)

  Throughout his article, Joshua Blumenstock affirms that new sources of data can be used to better the lives of those who need help the most, but only if used in conjunction with other means of information, such as conventional data sources that have been well established over several years. Blumenstock describes one of the pitfalls as resulting in unanticipated effects, such as poverty cycles resultant of high interest 'payday' loans, while also citing a study in Rwanda claiming that only 51% of borrowers even understood that they were being charged interest at all. He then goes on to explain how more conventional data collection methods, such as surveys and in-person interviews—while imperfect and less efficient—are well documented with known limitations and consequences. Meanwhile, with data collected from satellites and cell phones, certain populations can be selected against due to imperfect machine-learning algorithms. Blumenstock ends his list of pitfalls by explaining how conventional data are controlled and disseminated by governmental bodies, but artificial-intelligence programs are primarily owned by private entities who " have little incentive to do anything except maximize profits." 

  Blumenstock goes on to describe potential solutions to these pitfalls by demonstrating that new big data issues can be resolved by utilizing them hand-in-hand with more conventional data sources that will add validity and bolster the integrity of such data. Also, more work is yet to be completed regarding customizing algorithms to fit varying localities. Likewise, with greater collaboration between organizations that have the ability to manage such data—as the cited company DataKind aims to accomplish—superior innovations and efficacy can be achieved. 

  When considering the intersection between human development and data science, it is difficult to tread the fine line between rushing technological innovations and keeping in mind the primary goal—to help those in poverty or caught in disaster achieve greater prosperity. Good intent is undoubtedly not enough to justify ruining the lives of individuals. If machine-learning is used to identify populations in need, if those algorithms wrongly prejudice against other populations who may be more in need, these issues need to be swiftly identified and eliminated while also accepting proper consequences, without just claiming that the intention was to accomplish something good. In the end, when dealing with big data, there must be made an effort to limit negative consequences and ensure quality results, resultant of a humbler data science. 
